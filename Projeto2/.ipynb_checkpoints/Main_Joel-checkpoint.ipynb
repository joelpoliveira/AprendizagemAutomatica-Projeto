{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea841de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, max_error, f1_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3232268d-f3e0-47a6-89d2-5c14a2337928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4564, 42)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"biodegradable_a.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129e7f99-5a34-4e39-89e7-2810f207dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"Biodegradable\")\n",
    "y = df.Biodegradable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6fb2da6-1fe4-459e-b983-74091961c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new biodegradable (new_x):  1 if RB else -1\n",
    "y = y.map(lambda x: 1 if x=='RB' else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95953047-56d4-49c0-9389-368b06367624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação do train + test e validation set\n",
    "X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size=0.25, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe0f7f0e-fa37-4a5e-9679-bbbfa03c0ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3423 entries, 4057 to 2933\n",
      "Data columns (total 41 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   SpMax_L   3423 non-null   float64\n",
      " 1   J_Dz(e)   3423 non-null   float64\n",
      " 2   nHM       3423 non-null   float64\n",
      " 3   F01       3034 non-null   float64\n",
      " 4   F04       3423 non-null   float64\n",
      " 5   NssssC    3423 non-null   float64\n",
      " 6   nCb       3423 non-null   float64\n",
      " 7   C         2850 non-null   float64\n",
      " 8   nCp       2926 non-null   float64\n",
      " 9   nO        3423 non-null   float64\n",
      " 10  F03       3423 non-null   float64\n",
      " 11  SdssC     3423 non-null   float64\n",
      " 12  HyWi_B    3076 non-null   float64\n",
      " 13  LOC       3423 non-null   float64\n",
      " 14  SM6_L     3423 non-null   float64\n",
      " 15  F03_CO    3396 non-null   float64\n",
      " 16  Me        3091 non-null   float64\n",
      " 17  Mi        3423 non-null   float64\n",
      " 18  nN_N      3423 non-null   float64\n",
      " 19  nArNO2    3423 non-null   float64\n",
      " 20  nCRX3     3423 non-null   float64\n",
      " 21  SpPosA_B  3423 non-null   float64\n",
      " 22  nCIR      3050 non-null   float64\n",
      " 23  B01       3423 non-null   float64\n",
      " 24  B03       3423 non-null   float64\n",
      " 25  N_073     3423 non-null   float64\n",
      " 26  SpMax_A   2929 non-null   float64\n",
      " 27  Psi_i_1d  3423 non-null   float64\n",
      " 28  B04       3423 non-null   float64\n",
      " 29  SdO       3257 non-null   float64\n",
      " 30  TI2_L     3423 non-null   float64\n",
      " 31  nCrt      3246 non-null   float64\n",
      " 32  C_026     3423 non-null   float64\n",
      " 33  F02_CN    3423 non-null   float64\n",
      " 34  nHDon     3423 non-null   float64\n",
      " 35  SpMax_B   2420 non-null   float64\n",
      " 36  Psi_i_A   3106 non-null   float64\n",
      " 37  nN        3423 non-null   float64\n",
      " 38  SM6_B     3423 non-null   float64\n",
      " 39  nArCOOR   3423 non-null   float64\n",
      " 40  nX        2910 non-null   float64\n",
      "dtypes: float64(41)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "X_Train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dece845d-bca0-46d5-a758-98a6317ac1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum missing attributes on the rows: 6\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Maximum missing attributes on the rows: {X_Train.isna().sum(axis=1).max()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7033c5d1-4302-421f-a0d0-acf35d114eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F01         389\n",
       "C           573\n",
       "nCp         497\n",
       "HyWi_B      347\n",
       "F03_CO       27\n",
       "Me          332\n",
       "nCIR        373\n",
       "SpMax_A     494\n",
       "SdO         166\n",
       "nCrt        177\n",
       "SpMax_B    1003\n",
       "Psi_i_A     317\n",
       "nX          513\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_cols = X_Train.isna().sum()\n",
    "missing_cols[missing_cols>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ab5e9-30fa-4fdf-93ed-c35fd21ab2ca",
   "metadata": {},
   "source": [
    "Number of null values is significant on many columns ( > 25% ) <br>\n",
    "Droping features is not an option for dealing with missing data, because we do not have the knowledge yet if they have relation with the class we want to predict<br>\n",
    "\n",
    "However, per sample, 6 out of 40 attributes doesn't seem very significant.\n",
    "This before the feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eedb695-402b-4ef7-a6df-bb45192fe246",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classification Models\n",
    "\n",
    "- [ ] Logit\n",
    "- [ ] LDA\n",
    "- [ ] SVM\n",
    "- [ ] Naive Bayes\n",
    "- [ ] DecisionTree\n",
    "- [ ] KNN\n",
    "- [ ] Bagging\n",
    "- [ ] Boosting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1400eb92-925f-4665-9e7a-39ffb4b69dd7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Testing Imputation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e44b0-6023-453e-8bd4-c19432d2dbfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2bd24b5-9e87-4e80-9294-0f9fe13071e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_not_nan = X_Train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75c49ff8-be8d-4ded-8bce-130095fbee5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(698, 41)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_not_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0959cd7-0543-43af-87e8-0e6e3da41ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3423, 41)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3fa52d-c034-4f15-99c9-42ec6c127636",
   "metadata": {},
   "source": [
    "The difference in the number of rows, from the variable *X_train_not_nan* and the variable *X_train* indicates that a huge number of instances are missing at least one of the features, hence droping rows is not a viable option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51957cd9-b808-41ee-8759-fc245fc0fb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priors = X_Train.isna().sum()/X_Train.shape[0]\n",
    "priors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0de6a24-dcb5-46bc-84f3-4968cd1bdfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(X,priors):\n",
    "    masks = np.empty(shape = X.shape, dtype=np.bool_)\n",
    "    for i, p in enumerate(priors):\n",
    "        masks[:, i] = np.random.choice((True,False), size=masks.shape[0], p=(p,1-p))\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9743cae7-995a-42ba-9aa4-0d368758acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(X_train_not_nan)\n",
    "X_train_not_nan_scaled = pd.DataFrame(data = scaler.transform(X_train_not_nan),\n",
    "                                      columns=X_train_not_nan.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5cc1b69-58f0-4241-a3ab-1067ce969cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "masks = [get_mask(X_train_not_nan, priors) for _ in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3206bb6d-d13e-440c-9138-14b30bb30af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputers = (\n",
    "        SimpleImputer(),\n",
    "        SimpleImputer(strategy=\"median\"),\n",
    "        KNNImputer()\n",
    ")\n",
    "labels = [\"SimpleImpute_mean\", \"SimpleImpute_median\", \"KNN\"]\n",
    "\n",
    "results = pd.DataFrame(index=X_train_not_nan.columns)\n",
    "for label, model in zip(labels,imputers):\n",
    "    errors=pd.DataFrame(columns = X_train_not_nan.columns)\n",
    "    for _ in range(N):\n",
    "        X_masked = X_train_not_nan_scaled.mask(masks[_])\n",
    "        \n",
    "        model = model.fit(X_masked)\n",
    "        X_imputed = model.transform(X_masked)\n",
    "\n",
    "        errors.loc[_] = dict(zip(X_train_not_nan_scaled.columns, \n",
    "                                 mean_squared_error(X_train_not_nan_scaled, \n",
    "                                                    X_imputed, \n",
    "                                                    squared=False, \n",
    "                                                    multioutput=\"raw_values\")\n",
    "                                ))\n",
    "    results[label] = errors.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95896c1c-8457-4562-aa71-dba67806ba46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimpleImpute_mean</th>\n",
       "      <th>SimpleImpute_median</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F01</th>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.007659</td>\n",
       "      <td>0.008324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.070528</td>\n",
       "      <td>0.071237</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCp</th>\n",
       "      <td>0.044630</td>\n",
       "      <td>0.045187</td>\n",
       "      <td>0.032091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HyWi_B</th>\n",
       "      <td>0.041045</td>\n",
       "      <td>0.041094</td>\n",
       "      <td>0.015498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F03_CO</th>\n",
       "      <td>0.015056</td>\n",
       "      <td>0.015548</td>\n",
       "      <td>0.007097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Me</th>\n",
       "      <td>0.032115</td>\n",
       "      <td>0.032364</td>\n",
       "      <td>0.016534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCIR</th>\n",
       "      <td>0.023859</td>\n",
       "      <td>0.027678</td>\n",
       "      <td>0.015375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpMax_A</th>\n",
       "      <td>0.044225</td>\n",
       "      <td>0.044246</td>\n",
       "      <td>0.018480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SdO</th>\n",
       "      <td>0.040453</td>\n",
       "      <td>0.040772</td>\n",
       "      <td>0.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCrt</th>\n",
       "      <td>0.008774</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.007475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpMax_B</th>\n",
       "      <td>0.042138</td>\n",
       "      <td>0.042343</td>\n",
       "      <td>0.026547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Psi_i_A</th>\n",
       "      <td>0.047040</td>\n",
       "      <td>0.047580</td>\n",
       "      <td>0.020293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nX</th>\n",
       "      <td>0.017686</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.010875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SimpleImpute_mean  SimpleImpute_median       KNN\n",
       "F01               0.008584             0.007659  0.008324\n",
       "C                 0.070528             0.071237  0.028571\n",
       "nCp               0.044630             0.045187  0.032091\n",
       "HyWi_B            0.041045             0.041094  0.015498\n",
       "F03_CO            0.015056             0.015548  0.007097\n",
       "Me                0.032115             0.032364  0.016534\n",
       "nCIR              0.023859             0.027678  0.015375\n",
       "SpMax_A           0.044225             0.044246  0.018480\n",
       "SdO               0.040453             0.040772  0.016600\n",
       "nCrt              0.008774             0.007801  0.007475\n",
       "SpMax_B           0.042138             0.042343  0.026547\n",
       "Psi_i_A           0.047040             0.047580  0.020293\n",
       "nX                0.017686             0.017742  0.010875"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results>0].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78a7f464-4567-4c63-bb44-d9fe6aa47350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImpute_mean      0.436133\n",
       "SimpleImpute_median    0.441253\n",
       "KNN                    0.223760\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results>0].dropna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ec36b-db6f-4612-8b90-41729d797d0f",
   "metadata": {},
   "source": [
    "The *KNNImputer* is the one that better predicts the missing values, according to this test, since it is the one that gets closer results for every feature with missing values, which results having the least summed error. <br>\n",
    "Not many different parameters were used for it, so it can probably achieve even better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a054a774-6f41-4b07-b631-c528f9821615",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f7c4374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01</th>\n",
       "      <th>F04</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb</th>\n",
       "      <th>C</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>...</th>\n",
       "      <th>C_026</th>\n",
       "      <th>F02_CN</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "      <th>Biodegradable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>3.776854</td>\n",
       "      <td>2.408741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.177099</td>\n",
       "      <td>2.479789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.967228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>4.207577</td>\n",
       "      <td>3.405557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.552206</td>\n",
       "      <td>4.118984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.700636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>4.650000</td>\n",
       "      <td>4.031300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.527000</td>\n",
       "      <td>2.372000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.131000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>4.500517</td>\n",
       "      <td>3.039395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.511390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.096866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351</th>\n",
       "      <td>4.344574</td>\n",
       "      <td>3.645214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.457361</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.423525</td>\n",
       "      <td>3.051219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.743159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>4.868000</td>\n",
       "      <td>3.025200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.261000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>3.974877</td>\n",
       "      <td>2.917110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.233164</td>\n",
       "      <td>1.800985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.136023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>4.292865</td>\n",
       "      <td>3.156162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.934010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.344344</td>\n",
       "      <td>2.044372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.317020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>4.596000</td>\n",
       "      <td>3.416100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.992000</td>\n",
       "      <td>2.569000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.812000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>5.013900</td>\n",
       "      <td>2.968356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.276322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.775951</td>\n",
       "      <td>2.690665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.800764</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3423 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SpMax_L   J_Dz(e)  nHM  F01  F04  NssssC  nCb          C  nCp   nO  \\\n",
       "4057  3.776854  2.408741  0.0  0.0  0.0     0.0  0.0  30.000000  2.0  0.0   \n",
       "4322  4.207577  3.405557  0.0  0.0  0.0     0.0  0.0  25.000000  1.0  2.0   \n",
       "194   4.650000  4.031300  0.0  0.0  1.0     0.0  0.0  31.300000  3.0  2.0   \n",
       "2202  4.500517  3.039395  0.0  0.0  0.0     0.0  2.0        NaN  0.0  0.0   \n",
       "4351  4.344574  3.645214  0.0  0.0  0.0     0.0  0.0  31.457361  2.0  3.0   \n",
       "...        ...       ...  ...  ...  ...     ...  ...        ...  ...  ...   \n",
       "989   4.868000  3.025200  0.0  0.0  1.0     0.0  0.0  34.800000  3.0  1.0   \n",
       "2527  3.974877  2.917110  0.0  0.0  0.0     0.0  0.0        NaN  2.0  0.0   \n",
       "2952  4.292865  3.156162  0.0  0.0  0.0     0.0  0.0  33.934010  2.0  2.0   \n",
       "356   4.596000  3.416100  2.0  0.0  0.0     0.0  0.0  45.500000  0.0  0.0   \n",
       "2933  5.013900  2.968356  0.0  0.0  0.0     0.0  2.0  45.276322  0.0  4.0   \n",
       "\n",
       "      ...  C_026  F02_CN  nHDon   SpMax_B   Psi_i_A   nN     SM6_B  nArCOOR  \\\n",
       "4057  ...    0.0     0.0    0.0  3.177099  2.479789  0.0  6.967228      0.0   \n",
       "4322  ...    0.0     0.0    1.0  3.552206  4.118984  0.0  7.700636      0.0   \n",
       "194   ...    0.0     3.0    0.0  3.527000  2.372000  1.0  8.131000      0.0   \n",
       "2202  ...    0.0     0.0    1.0       NaN  2.511390  1.0  8.096866      0.0   \n",
       "4351  ...    0.0     0.0    1.0  3.423525  3.051219  0.0  7.743159      0.0   \n",
       "...   ...    ...     ...    ...       ...       ...  ...       ...      ...   \n",
       "989   ...    0.0     5.0    1.0       NaN       NaN  2.0  8.261000      0.0   \n",
       "2527  ...    0.0     0.0    0.0  3.233164  1.800985  0.0  8.136023      0.0   \n",
       "2952  ...    0.0     0.0    0.0  3.344344  2.044372  0.0  8.317020      0.0   \n",
       "356   ...    0.0     2.0    0.0  3.992000  2.569000  1.0  8.812000      0.0   \n",
       "2933  ...    0.0     0.0    0.0  3.775951  2.690665  0.0  8.800764      2.0   \n",
       "\n",
       "       nX  Biodegradable  \n",
       "4057  0.0              1  \n",
       "4322  NaN              1  \n",
       "194   0.0              1  \n",
       "2202  0.0              1  \n",
       "4351  NaN              1  \n",
       "...   ...            ...  \n",
       "989   NaN             -1  \n",
       "2527  0.0              1  \n",
       "2952  NaN              1  \n",
       "356   2.0             -1  \n",
       "2933  0.0              1  \n",
       "\n",
       "[3423 rows x 42 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat( (X_Train, y_Train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8490cb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01</th>\n",
       "      <th>F04</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb</th>\n",
       "      <th>C</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>...</th>\n",
       "      <th>nCrt</th>\n",
       "      <th>C_026</th>\n",
       "      <th>F02_CN</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230733</td>\n",
       "      <td>1.389010</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>1.025951</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>-0.400740</td>\n",
       "      <td>1.488723</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>2.457302</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>-0.100319</td>\n",
       "      <td>-0.438917</td>\n",
       "      <td>1.213572</td>\n",
       "      <td>0.024492</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.261726</td>\n",
       "      <td>0.682137</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>1.167032</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>-1.006461</td>\n",
       "      <td>2.322026</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>1.036755</td>\n",
       "      <td>-0.489638</td>\n",
       "      <td>0.353644</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>-0.902555</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.163050</td>\n",
       "      <td>-0.299268</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>0.169325</td>\n",
       "      <td>0.895370</td>\n",
       "      <td>-0.177883</td>\n",
       "      <td>0.642670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>0.179344</td>\n",
       "      <td>0.031227</td>\n",
       "      <td>-0.235835</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>0.100488</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023820</td>\n",
       "      <td>0.060363</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>0.169325</td>\n",
       "      <td>1.419572</td>\n",
       "      <td>-1.011186</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>0.114656</td>\n",
       "      <td>0.382507</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>-0.009828</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.193804</td>\n",
       "      <td>-0.517543</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>-0.421137</td>\n",
       "      <td>0.655420</td>\n",
       "      <td>-1.390186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>-0.975716</td>\n",
       "      <td>-1.355502</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>-0.703168</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>-0.128030</td>\n",
       "      <td>0.289936</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>-0.273512</td>\n",
       "      <td>-0.177883</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>-0.312834</td>\n",
       "      <td>-0.692220</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>0.410503</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>2.407050</td>\n",
       "      <td>-1.678164</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>2.462085</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>0.083838</td>\n",
       "      <td>0.655420</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>...</td>\n",
       "      <td>5.059796</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>1.036755</td>\n",
       "      <td>0.101377</td>\n",
       "      <td>-0.878552</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>0.072831</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>1.540535</td>\n",
       "      <td>1.441187</td>\n",
       "      <td>2.241214</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>1.167032</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>-1.006461</td>\n",
       "      <td>2.322026</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>1.036755</td>\n",
       "      <td>5.132820</td>\n",
       "      <td>0.136108</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>4.457771</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>1.046530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0.122419</td>\n",
       "      <td>0.463956</td>\n",
       "      <td>2.241214</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>1.319510</td>\n",
       "      <td>-1.011186</td>\n",
       "      <td>-1.390186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>1.526142</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>0.626723</td>\n",
       "      <td>-0.139235</td>\n",
       "      <td>1.213572</td>\n",
       "      <td>0.756031</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>1.046530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0.960651</td>\n",
       "      <td>-0.209301</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>0.922122</td>\n",
       "      <td>1.292413</td>\n",
       "      <td>-1.011186</td>\n",
       "      <td>1.320289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>0.288923</td>\n",
       "      <td>0.045846</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>0.743961</td>\n",
       "      <td>4.619273</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>698 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SpMax_L   J_Dz(e)       nHM       F01       F04    NssssC       nCb  \\\n",
       "0    0.230733  1.389010 -0.232094 -0.071715  1.025951 -0.128021 -0.583471   \n",
       "1    1.261726  0.682137 -0.232094 -0.071715 -0.255111  1.167032 -0.583471   \n",
       "2    0.163050 -0.299268 -0.232094 -0.071715 -0.255111 -0.128021  0.169325   \n",
       "3    0.023820  0.060363 -0.232094 -0.071715 -0.255111 -0.128021  0.169325   \n",
       "4   -1.193804 -0.517543 -0.232094 -0.071715 -0.255111 -0.128021 -0.583471   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "693 -0.128030  0.289936 -0.232094 -0.071715 -0.255111 -0.128021 -0.583471   \n",
       "694  2.407050 -1.678164 -0.232094 -0.071715 -0.255111  2.462085 -0.583471   \n",
       "695  1.540535  1.441187  2.241214 -0.071715 -0.255111  1.167032 -0.583471   \n",
       "696  0.122419  0.463956  2.241214 -0.071715 -0.255111 -0.128021 -0.583471   \n",
       "697  0.960651 -0.209301 -0.232094 -0.071715 -0.255111 -0.128021  0.922122   \n",
       "\n",
       "            C       nCp        nO  ...      nCrt     C_026    F02_CN  \\\n",
       "0   -0.400740  1.488723 -0.034949  ... -0.096025 -0.335282  2.457302   \n",
       "1   -1.006461  2.322026 -0.034949  ... -0.096025 -0.335282 -0.336178   \n",
       "2    0.895370 -0.177883  0.642670  ... -0.096025 -0.335282 -0.336178   \n",
       "3    1.419572 -1.011186 -0.034949  ... -0.096025 -0.335282 -0.336178   \n",
       "4   -0.421137  0.655420 -1.390186  ... -0.096025 -0.335282 -0.336178   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "693 -0.273512 -0.177883 -0.034949  ... -0.096025 -0.335282 -0.336178   \n",
       "694  0.083838  0.655420 -0.034949  ...  5.059796 -0.335282 -0.336178   \n",
       "695 -1.006461  2.322026 -0.034949  ... -0.096025 -0.335282 -0.336178   \n",
       "696  1.319510 -1.011186 -1.390186  ... -0.096025 -0.335282  1.526142   \n",
       "697  1.292413 -1.011186  1.320289  ... -0.096025 -0.335282 -0.336178   \n",
       "\n",
       "        nHDon   SpMax_B   Psi_i_A        nN     SM6_B   nArCOOR        nX  \n",
       "0   -0.678067 -0.100319 -0.438917  1.213572  0.024492 -0.225584 -0.139311  \n",
       "1    1.036755 -0.489638  0.353644 -0.399901 -0.902555 -0.225584 -0.139311  \n",
       "2    0.179344  0.031227 -0.235835 -0.399901  0.100488 -0.225584 -0.139311  \n",
       "3   -0.678067  0.114656  0.382507 -0.399901 -0.009828 -0.225584 -0.139311  \n",
       "4   -0.678067 -0.975716 -1.355502 -0.399901 -0.703168 -0.225584 -0.139311  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "693 -0.678067 -0.312834 -0.692220 -0.399901  0.410503 -0.225584 -0.139311  \n",
       "694  1.036755  0.101377 -0.878552 -0.399901  0.072831 -0.225584 -0.139311  \n",
       "695  1.036755  5.132820  0.136108 -0.399901  4.457771 -0.225584  1.046530  \n",
       "696 -0.678067  0.626723 -0.139235  1.213572  0.756031 -0.225584  1.046530  \n",
       "697 -0.678067  0.288923  0.045846 -0.399901  0.743961  4.619273 -0.139311  \n",
       "\n",
       "[698 rows x 41 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalização por Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_Train_scaled=scaler.fit_transform(X_train_not_nan)\n",
    "X_train_stdScaler=pd.DataFrame(\n",
    "    data = X_Train_scaled,\n",
    "    columns=X_Train.columns\n",
    ")\n",
    "X_train_stdScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e74d2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputers = (\n",
    "        SimpleImputer(),\n",
    "        SimpleImputer(strategy=\"median\"),\n",
    "        KNNImputer()\n",
    ")\n",
    "labels = [\"SimpleImpute_mean\", \"SimpleImpute_median\", \"KNN\"]\n",
    "\n",
    "results = pd.DataFrame(index=X_train_not_nan.columns)\n",
    "for label, model in zip(labels,imputers):\n",
    "    errors=pd.DataFrame(columns = X_train_not_nan.columns)\n",
    "    for _ in range(N):\n",
    "        X_masked = X_train_stdScaler.mask(masks[_])\n",
    "        \n",
    "        model = model.fit(X_masked)\n",
    "        X_imputed = model.transform(X_masked)\n",
    "\n",
    "        errors.loc[_] = dict(zip(X_train_stdScaler.columns, \n",
    "                                 mean_squared_error(X_train_stdScaler, \n",
    "                                                    X_imputed, \n",
    "                                                    squared=False, \n",
    "                                                    multioutput=\"raw_values\")\n",
    "                                ))\n",
    "    results[label] = errors.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f76c393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimpleImpute_mean</th>\n",
       "      <th>SimpleImpute_median</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F01</th>\n",
       "      <td>0.171867</td>\n",
       "      <td>0.153363</td>\n",
       "      <td>0.150897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.404990</td>\n",
       "      <td>0.409060</td>\n",
       "      <td>0.152144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCp</th>\n",
       "      <td>0.371907</td>\n",
       "      <td>0.376549</td>\n",
       "      <td>0.262769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HyWi_B</th>\n",
       "      <td>0.313925</td>\n",
       "      <td>0.314297</td>\n",
       "      <td>0.112303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F03_CO</th>\n",
       "      <td>0.080004</td>\n",
       "      <td>0.082622</td>\n",
       "      <td>0.036944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Me</th>\n",
       "      <td>0.298827</td>\n",
       "      <td>0.301147</td>\n",
       "      <td>0.161031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCIR</th>\n",
       "      <td>0.289752</td>\n",
       "      <td>0.336135</td>\n",
       "      <td>0.186764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpMax_A</th>\n",
       "      <td>0.373608</td>\n",
       "      <td>0.373784</td>\n",
       "      <td>0.154110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SdO</th>\n",
       "      <td>0.211210</td>\n",
       "      <td>0.212875</td>\n",
       "      <td>0.089215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCrt</th>\n",
       "      <td>0.135704</td>\n",
       "      <td>0.120664</td>\n",
       "      <td>0.106052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpMax_B</th>\n",
       "      <td>0.534457</td>\n",
       "      <td>0.537053</td>\n",
       "      <td>0.302388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Psi_i_A</th>\n",
       "      <td>0.305627</td>\n",
       "      <td>0.309136</td>\n",
       "      <td>0.128358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nX</th>\n",
       "      <td>0.283139</td>\n",
       "      <td>0.284032</td>\n",
       "      <td>0.196150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SimpleImpute_mean  SimpleImpute_median       KNN\n",
       "F01               0.171867             0.153363  0.150897\n",
       "C                 0.404990             0.409060  0.152144\n",
       "nCp               0.371907             0.376549  0.262769\n",
       "HyWi_B            0.313925             0.314297  0.112303\n",
       "F03_CO            0.080004             0.082622  0.036944\n",
       "Me                0.298827             0.301147  0.161031\n",
       "nCIR              0.289752             0.336135  0.186764\n",
       "SpMax_A           0.373608             0.373784  0.154110\n",
       "SdO               0.211210             0.212875  0.089215\n",
       "nCrt              0.135704             0.120664  0.106052\n",
       "SpMax_B           0.534457             0.537053  0.302388\n",
       "Psi_i_A           0.305627             0.309136  0.128358\n",
       "nX                0.283139             0.284032  0.196150"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results>0].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7a55c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImpute_mean      3.775017\n",
       "SimpleImpute_median    3.810716\n",
       "KNN                    2.039125\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results>0].dropna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f886e14c-978a-492d-a360-fbd0abb86f0d",
   "metadata": {},
   "source": [
    "Similarmente ao caso do MinMaxScaler, o KNN imputer obtém o menor erro nas previsões dos valores em falta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60e59f-3276-4400-9493-36543dfbacfa",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce4c18d4-552b-4c09-b31d-6c0b4a8ac7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [(\"scaler\", MinMaxScaler()),\n",
    "            (\"imputer\", KNNImputer(n_neighbors=4)),\n",
    "            (\"classifier\", RandomForestClassifier(n_estimators=200, random_state=47))\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fab2680-0f08-451b-958d-1388c6f3134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........... (step 2 of 3) Processing imputer, total=   1.0s\n",
      "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   2.0s\n"
     ]
    }
   ],
   "source": [
    "rf = Pipeline(pipeline, verbose=True).fit(X_Train, y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db0e059-11f1-4a95-a08a-6ee962a9e8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04161385, 0.02280242, 0.08690971, 0.00286961, 0.05453298,\n",
       "       0.05805409, 0.05803263, 0.02117278, 0.0168544 , 0.01224928,\n",
       "       0.04468076, 0.02097033, 0.01906134, 0.01992376, 0.02458327,\n",
       "       0.01232904, 0.02018489, 0.02319297, 0.00092807, 0.00505014,\n",
       "       0.00024832, 0.04060187, 0.02513782, 0.00049472, 0.01352648,\n",
       "       0.0004414 , 0.03450688, 0.01420294, 0.00019239, 0.01625675,\n",
       "       0.01686838, 0.01450246, 0.01740904, 0.04024602, 0.00640186,\n",
       "       0.0490711 , 0.02541953, 0.01951893, 0.03622532, 0.00074949,\n",
       "       0.06198195])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf[\"classifier\"].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b7d819f-148f-452f-8c31-2a141cf2823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_labels(col_names : list[str], pipeline: Pipeline) -> list[str]:\n",
    "    #join names and scores in tuples (column, score)\n",
    "    label_scores = zip(col_names, pipeline[\"classifier\"].feature_importances_)\n",
    "    #sort tuples accoding to value in index 1 (column, -> score <-)\n",
    "    sorted_labels = sorted(label_scores, key = lambda x: x[1], reverse=True)\n",
    "    #return only the column labels, sorted\n",
    "    return list(map(lambda x: x[0], sorted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b421d05-b8f4-4272-b786-f4203530b10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nHM',\n",
       " 'nX',\n",
       " 'NssssC',\n",
       " 'nCb',\n",
       " 'F04',\n",
       " 'SpMax_B',\n",
       " 'F03',\n",
       " 'SpMax_L',\n",
       " 'SpPosA_B',\n",
       " 'F02_CN',\n",
       " 'SM6_B',\n",
       " 'SpMax_A',\n",
       " 'Psi_i_A',\n",
       " 'nCIR',\n",
       " 'SM6_L',\n",
       " 'Mi',\n",
       " 'J_Dz(e)',\n",
       " 'C',\n",
       " 'SdssC',\n",
       " 'Me',\n",
       " 'LOC',\n",
       " 'nN',\n",
       " 'HyWi_B',\n",
       " 'C_026',\n",
       " 'TI2_L',\n",
       " 'nCp',\n",
       " 'SdO',\n",
       " 'nCrt',\n",
       " 'Psi_i_1d',\n",
       " 'B03',\n",
       " 'F03_CO',\n",
       " 'nO',\n",
       " 'nHDon',\n",
       " 'nArNO2',\n",
       " 'F01',\n",
       " 'nN_N',\n",
       " 'nArCOOR',\n",
       " 'B01',\n",
       " 'N_073',\n",
       " 'nCRX3',\n",
       " 'B04']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sorted_labels(X_Train.columns, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a599e2-f6ec-4df1-bd10-8f0aff80501f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7328c2-5f90-4b10-abbe-da1eda9b1df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9bb54c-cbf6-4d92-8c71-ef54f5a1a831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2d9bd-be8e-43b8-957f-85aeeece3688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e473ff82-4ecf-4a28-be39-6fd635291d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scalar\", MinMaxScaler()),\n",
    "    (\"imputer\", KNNImputer(n_neighbors=4)),\n",
    "    (\"predicter\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62f77834-99c5-4ed9-8bc3-ecc0276e0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"imputer__n_neighbors\" : range(2,4+1),\n",
    "    \"imputer__weights\": [\"uniform\", \"distance\"],\n",
    "    #\"predicter__penalty\": ['l1', 'l2']\n",
    "}\n",
    "\n",
    "results = GridSearchCV(model, grid).fit(X_Train, y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ddf1c85e-f51c-4642-a96c-a9b6a97339c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imputer__n_neighbors': 4, 'imputer__weights': 'uniform'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d650ab6f-c0ca-44d2-9820-5fb4990e8012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scalar&#x27;, MinMaxScaler()),\n",
       "                (&#x27;imputer&#x27;, KNNImputer(n_neighbors=4)),\n",
       "                (&#x27;predicter&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scalar&#x27;, MinMaxScaler()),\n",
       "                (&#x27;imputer&#x27;, KNNImputer(n_neighbors=4)),\n",
       "                (&#x27;predicter&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer(n_neighbors=4)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scalar', MinMaxScaler()),\n",
       "                ('imputer', KNNImputer(n_neighbors=4)),\n",
       "                ('predicter', LogisticRegression())])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62457b10-54df-4587-b42e-9df5900426a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imputer__n_neighbors': 4, 'imputer__weights': 'uniform'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "806533c4-5a00-4ed1-a3aa-16d61cdec9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_results = [results]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4920b7-f741-4186-ac7f-5cd8e3287773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
