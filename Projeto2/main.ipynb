{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8ea841de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, max_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3232268d-f3e0-47a6-89d2-5c14a2337928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4564, 42)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"biodegradable_a.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "129e7f99-5a34-4e39-89e7-2810f207dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"Biodegradable\")\n",
    "y = df.Biodegradable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a6fb2da6-1fe4-459e-b983-74091961c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new biodegradable (new_x):  1 if RB else -1\n",
    "y = y.map(lambda x: 1 if x=='RB' else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "95953047-56d4-49c0-9389-368b06367624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação do train + test e validation set\n",
    "X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size=0.25, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fe0f7f0e-fa37-4a5e-9679-bbbfa03c0ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3423 entries, 4057 to 2933\n",
      "Data columns (total 41 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   SpMax_L   3423 non-null   float64\n",
      " 1   J_Dz(e)   3423 non-null   float64\n",
      " 2   nHM       3423 non-null   float64\n",
      " 3   F01       3034 non-null   float64\n",
      " 4   F04       3423 non-null   float64\n",
      " 5   NssssC    3423 non-null   float64\n",
      " 6   nCb       3423 non-null   float64\n",
      " 7   C         2850 non-null   float64\n",
      " 8   nCp       2926 non-null   float64\n",
      " 9   nO        3423 non-null   float64\n",
      " 10  F03       3423 non-null   float64\n",
      " 11  SdssC     3423 non-null   float64\n",
      " 12  HyWi_B    3076 non-null   float64\n",
      " 13  LOC       3423 non-null   float64\n",
      " 14  SM6_L     3423 non-null   float64\n",
      " 15  F03_CO    3396 non-null   float64\n",
      " 16  Me        3091 non-null   float64\n",
      " 17  Mi        3423 non-null   float64\n",
      " 18  nN_N      3423 non-null   float64\n",
      " 19  nArNO2    3423 non-null   float64\n",
      " 20  nCRX3     3423 non-null   float64\n",
      " 21  SpPosA_B  3423 non-null   float64\n",
      " 22  nCIR      3050 non-null   float64\n",
      " 23  B01       3423 non-null   float64\n",
      " 24  B03       3423 non-null   float64\n",
      " 25  N_073     3423 non-null   float64\n",
      " 26  SpMax_A   2929 non-null   float64\n",
      " 27  Psi_i_1d  3423 non-null   float64\n",
      " 28  B04       3423 non-null   float64\n",
      " 29  SdO       3257 non-null   float64\n",
      " 30  TI2_L     3423 non-null   float64\n",
      " 31  nCrt      3246 non-null   float64\n",
      " 32  C_026     3423 non-null   float64\n",
      " 33  F02_CN    3423 non-null   float64\n",
      " 34  nHDon     3423 non-null   float64\n",
      " 35  SpMax_B   2420 non-null   float64\n",
      " 36  Psi_i_A   3106 non-null   float64\n",
      " 37  nN        3423 non-null   float64\n",
      " 38  SM6_B     3423 non-null   float64\n",
      " 39  nArCOOR   3423 non-null   float64\n",
      " 40  nX        2910 non-null   float64\n",
      "dtypes: float64(41)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "X_Train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dece845d-bca0-46d5-a758-98a6317ac1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum missing attributes on the rows: 6\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Maximum missing attributes on the rows: {X_Train.isna().sum(axis=1).max()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7033c5d1-4302-421f-a0d0-acf35d114eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F01         389\n",
       "C           573\n",
       "nCp         497\n",
       "HyWi_B      347\n",
       "F03_CO       27\n",
       "Me          332\n",
       "nCIR        373\n",
       "SpMax_A     494\n",
       "SdO         166\n",
       "nCrt        177\n",
       "SpMax_B    1003\n",
       "Psi_i_A     317\n",
       "nX          513\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_cols = X_Train.isna().sum()\n",
    "missing_cols[missing_cols>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ab5e9-30fa-4fdf-93ed-c35fd21ab2ca",
   "metadata": {},
   "source": [
    "Number of null values is significant on many columns ( > 25% ) <br>\n",
    "Droping features is not an option for dealing with missing data, because we do not have the knowledge yet if they have relation with the class we want to predict<br>\n",
    "\n",
    "However, per sample, 6 out of 40 attributes doesn't seem very significant.\n",
    "This before the feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eedb695-402b-4ef7-a6df-bb45192fe246",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classification Models\n",
    "\n",
    "- [ ] Logit\n",
    "- [ ] LDA\n",
    "- [ ] SVM\n",
    "- [ ] Naive Bayes\n",
    "- [ ] DecisionTree\n",
    "- [ ] KNN\n",
    "- [ ] Bagging\n",
    "- [ ] Boosting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1400eb92-925f-4665-9e7a-39ffb4b69dd7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Testing Imputation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e44b0-6023-453e-8bd4-c19432d2dbfc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e2bd24b5-9e87-4e80-9294-0f9fe13071e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_not_nan = X_Train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "75c49ff8-be8d-4ded-8bce-130095fbee5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(698, 41)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_not_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d0959cd7-0543-43af-87e8-0e6e3da41ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3423, 41)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3fa52d-c034-4f15-99c9-42ec6c127636",
   "metadata": {},
   "source": [
    "The difference in the number of rows, from the variable *X_train_not_nan* and the variable *X_train* indicates that a huge number of instances are missing at least one of the features, hence droping rows is not a viable option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "51957cd9-b808-41ee-8759-fc245fc0fb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priors = X_Train.isna().sum()/X_Train.shape[0]\n",
    "priors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e0de6a24-dcb5-46bc-84f3-4968cd1bdfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(X,priors):\n",
    "    masks = np.empty(shape = X.shape, dtype=np.bool_)\n",
    "    for i, p in enumerate(priors):\n",
    "        masks[:, i] = np.random.choice((True,False), size=masks.shape[0], p=(p,1-p))\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9743cae7-995a-42ba-9aa4-0d368758acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(X_train_not_nan)\n",
    "X_train_not_nan_scaled = pd.DataFrame(data = scaler.transform(X_train_not_nan),\n",
    "                                      columns=X_train_not_nan.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c5cc1b69-58f0-4241-a3ab-1067ce969cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "masks = [get_mask(X_train_not_nan, priors) for _ in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3206bb6d-d13e-440c-9138-14b30bb30af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputers = (\n",
    "        SimpleImputer(),\n",
    "        SimpleImputer(strategy=\"median\"),\n",
    "        KNNImputer()\n",
    ")\n",
    "labels = [\"SimpleImpute_mean\", \"SimpleImpute_median\", \"KNN\"]\n",
    "\n",
    "results = pd.DataFrame(index=X_train_not_nan.columns)\n",
    "for label, model in zip(labels,imputers):\n",
    "    errors=pd.DataFrame(columns = X_train_not_nan.columns)\n",
    "    for _ in range(N):\n",
    "        X_masked = X_train_not_nan_scaled.mask(masks[_])\n",
    "        \n",
    "        model = model.fit(X_masked)\n",
    "        X_imputed = model.transform(X_masked)\n",
    "\n",
    "        errors.loc[_] = dict(zip(X_train_not_nan_scaled.columns, \n",
    "                                 mean_squared_error(X_train_not_nan_scaled, \n",
    "                                                    X_imputed, \n",
    "                                                    squared=False, \n",
    "                                                    multioutput=\"raw_values\")\n",
    "                                ))\n",
    "    results[label] = errors.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "95896c1c-8457-4562-aa71-dba67806ba46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimpleImpute_mean</th>\n",
       "      <th>SimpleImpute_median</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F01</th>\n",
       "      <td>0.010483</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.010376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.071318</td>\n",
       "      <td>0.072185</td>\n",
       "      <td>0.029181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCp</th>\n",
       "      <td>0.045277</td>\n",
       "      <td>0.045892</td>\n",
       "      <td>0.033346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HyWi_B</th>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.041644</td>\n",
       "      <td>0.016341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F03_CO</th>\n",
       "      <td>0.015224</td>\n",
       "      <td>0.015884</td>\n",
       "      <td>0.007531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Me</th>\n",
       "      <td>0.032738</td>\n",
       "      <td>0.032997</td>\n",
       "      <td>0.017720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCIR</th>\n",
       "      <td>0.024946</td>\n",
       "      <td>0.028840</td>\n",
       "      <td>0.015923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpMax_A</th>\n",
       "      <td>0.044961</td>\n",
       "      <td>0.044988</td>\n",
       "      <td>0.018921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SdO</th>\n",
       "      <td>0.041475</td>\n",
       "      <td>0.041719</td>\n",
       "      <td>0.017390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCrt</th>\n",
       "      <td>0.008369</td>\n",
       "      <td>0.007460</td>\n",
       "      <td>0.007198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpMax_B</th>\n",
       "      <td>0.042025</td>\n",
       "      <td>0.042256</td>\n",
       "      <td>0.026722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Psi_i_A</th>\n",
       "      <td>0.046371</td>\n",
       "      <td>0.046663</td>\n",
       "      <td>0.019881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nX</th>\n",
       "      <td>0.019741</td>\n",
       "      <td>0.019816</td>\n",
       "      <td>0.012972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SimpleImpute_mean  SimpleImpute_median       KNN\n",
       "F01               0.010483             0.009649  0.010376\n",
       "C                 0.071318             0.072185  0.029181\n",
       "nCp               0.045277             0.045892  0.033346\n",
       "HyWi_B            0.041600             0.041644  0.016341\n",
       "F03_CO            0.015224             0.015884  0.007531\n",
       "Me                0.032738             0.032997  0.017720\n",
       "nCIR              0.024946             0.028840  0.015923\n",
       "SpMax_A           0.044961             0.044988  0.018921\n",
       "SdO               0.041475             0.041719  0.017390\n",
       "nCrt              0.008369             0.007460  0.007198\n",
       "SpMax_B           0.042025             0.042256  0.026722\n",
       "Psi_i_A           0.046371             0.046663  0.019881\n",
       "nX                0.019741             0.019816  0.012972"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results>0].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "78a7f464-4567-4c63-bb44-d9fe6aa47350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImpute_mean      0.444530\n",
       "SimpleImpute_median    0.449993\n",
       "KNN                    0.233503\n",
       "dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results>0].dropna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ec36b-db6f-4612-8b90-41729d797d0f",
   "metadata": {},
   "source": [
    "The *KNNImputer* is the one that better predicts the missing values, according to this test, since it is the one that gets closer results for every feature with missing values, which results having the least summed error. <br>\n",
    "Not many different parameters were used for it, so it can probably achieve even better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a054a774-6f41-4b07-b631-c528f9821615",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2f7c4374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01</th>\n",
       "      <th>F04</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb</th>\n",
       "      <th>C</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>...</th>\n",
       "      <th>C_026</th>\n",
       "      <th>F02_CN</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "      <th>Biodegradable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>3.776854</td>\n",
       "      <td>2.408741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.177099</td>\n",
       "      <td>2.479789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.967228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>4.207577</td>\n",
       "      <td>3.405557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.552206</td>\n",
       "      <td>4.118984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.700636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>4.650000</td>\n",
       "      <td>4.031300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.527000</td>\n",
       "      <td>2.372000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.131000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>4.500517</td>\n",
       "      <td>3.039395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.511390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.096866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351</th>\n",
       "      <td>4.344574</td>\n",
       "      <td>3.645214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.457361</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.423525</td>\n",
       "      <td>3.051219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.743159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>4.868000</td>\n",
       "      <td>3.025200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.261000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>3.974877</td>\n",
       "      <td>2.917110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.233164</td>\n",
       "      <td>1.800985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.136023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>4.292865</td>\n",
       "      <td>3.156162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.934010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.344344</td>\n",
       "      <td>2.044372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.317020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>4.596000</td>\n",
       "      <td>3.416100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.992000</td>\n",
       "      <td>2.569000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.812000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>5.013900</td>\n",
       "      <td>2.968356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.276322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.775951</td>\n",
       "      <td>2.690665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.800764</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3423 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SpMax_L   J_Dz(e)  nHM  F01  F04  NssssC  nCb          C  nCp   nO  \\\n",
       "4057  3.776854  2.408741  0.0  0.0  0.0     0.0  0.0  30.000000  2.0  0.0   \n",
       "4322  4.207577  3.405557  0.0  0.0  0.0     0.0  0.0  25.000000  1.0  2.0   \n",
       "194   4.650000  4.031300  0.0  0.0  1.0     0.0  0.0  31.300000  3.0  2.0   \n",
       "2202  4.500517  3.039395  0.0  0.0  0.0     0.0  2.0        NaN  0.0  0.0   \n",
       "4351  4.344574  3.645214  0.0  0.0  0.0     0.0  0.0  31.457361  2.0  3.0   \n",
       "...        ...       ...  ...  ...  ...     ...  ...        ...  ...  ...   \n",
       "989   4.868000  3.025200  0.0  0.0  1.0     0.0  0.0  34.800000  3.0  1.0   \n",
       "2527  3.974877  2.917110  0.0  0.0  0.0     0.0  0.0        NaN  2.0  0.0   \n",
       "2952  4.292865  3.156162  0.0  0.0  0.0     0.0  0.0  33.934010  2.0  2.0   \n",
       "356   4.596000  3.416100  2.0  0.0  0.0     0.0  0.0  45.500000  0.0  0.0   \n",
       "2933  5.013900  2.968356  0.0  0.0  0.0     0.0  2.0  45.276322  0.0  4.0   \n",
       "\n",
       "      ...  C_026  F02_CN  nHDon   SpMax_B   Psi_i_A   nN     SM6_B  nArCOOR  \\\n",
       "4057  ...    0.0     0.0    0.0  3.177099  2.479789  0.0  6.967228      0.0   \n",
       "4322  ...    0.0     0.0    1.0  3.552206  4.118984  0.0  7.700636      0.0   \n",
       "194   ...    0.0     3.0    0.0  3.527000  2.372000  1.0  8.131000      0.0   \n",
       "2202  ...    0.0     0.0    1.0       NaN  2.511390  1.0  8.096866      0.0   \n",
       "4351  ...    0.0     0.0    1.0  3.423525  3.051219  0.0  7.743159      0.0   \n",
       "...   ...    ...     ...    ...       ...       ...  ...       ...      ...   \n",
       "989   ...    0.0     5.0    1.0       NaN       NaN  2.0  8.261000      0.0   \n",
       "2527  ...    0.0     0.0    0.0  3.233164  1.800985  0.0  8.136023      0.0   \n",
       "2952  ...    0.0     0.0    0.0  3.344344  2.044372  0.0  8.317020      0.0   \n",
       "356   ...    0.0     2.0    0.0  3.992000  2.569000  1.0  8.812000      0.0   \n",
       "2933  ...    0.0     0.0    0.0  3.775951  2.690665  0.0  8.800764      2.0   \n",
       "\n",
       "       nX  Biodegradable  \n",
       "4057  0.0              1  \n",
       "4322  NaN              1  \n",
       "194   0.0              1  \n",
       "2202  0.0              1  \n",
       "4351  NaN              1  \n",
       "...   ...            ...  \n",
       "989   NaN             -1  \n",
       "2527  0.0              1  \n",
       "2952  NaN              1  \n",
       "356   2.0             -1  \n",
       "2933  0.0              1  \n",
       "\n",
       "[3423 rows x 42 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat( (X_Train, y_Train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8490cb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01</th>\n",
       "      <th>F04</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb</th>\n",
       "      <th>C</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>...</th>\n",
       "      <th>nCrt</th>\n",
       "      <th>C_026</th>\n",
       "      <th>F02_CN</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230733</td>\n",
       "      <td>1.389010</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>1.025951</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>-0.400740</td>\n",
       "      <td>1.488723</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>2.457302</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>-0.100319</td>\n",
       "      <td>-0.438917</td>\n",
       "      <td>1.213572</td>\n",
       "      <td>0.024492</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.261726</td>\n",
       "      <td>0.682137</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>1.167032</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>-1.006461</td>\n",
       "      <td>2.322026</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>1.036755</td>\n",
       "      <td>-0.489638</td>\n",
       "      <td>0.353644</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>-0.902555</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.163050</td>\n",
       "      <td>-0.299268</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>0.169325</td>\n",
       "      <td>0.895370</td>\n",
       "      <td>-0.177883</td>\n",
       "      <td>0.642670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>0.179344</td>\n",
       "      <td>0.031227</td>\n",
       "      <td>-0.235835</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>0.100488</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023820</td>\n",
       "      <td>0.060363</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>0.169325</td>\n",
       "      <td>1.419572</td>\n",
       "      <td>-1.011186</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>0.114656</td>\n",
       "      <td>0.382507</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>-0.009828</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.193804</td>\n",
       "      <td>-0.517543</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>-0.421137</td>\n",
       "      <td>0.655420</td>\n",
       "      <td>-1.390186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>-0.975716</td>\n",
       "      <td>-1.355502</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>-0.703168</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>-0.128030</td>\n",
       "      <td>0.289936</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>-0.273512</td>\n",
       "      <td>-0.177883</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>-0.312834</td>\n",
       "      <td>-0.692220</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>0.410503</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>2.407050</td>\n",
       "      <td>-1.678164</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>2.462085</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>0.083838</td>\n",
       "      <td>0.655420</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>...</td>\n",
       "      <td>5.059796</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>1.036755</td>\n",
       "      <td>0.101377</td>\n",
       "      <td>-0.878552</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>0.072831</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>1.540535</td>\n",
       "      <td>1.441187</td>\n",
       "      <td>2.241214</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>1.167032</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>-1.006461</td>\n",
       "      <td>2.322026</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>1.036755</td>\n",
       "      <td>5.132820</td>\n",
       "      <td>0.136108</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>4.457771</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>1.046530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0.122419</td>\n",
       "      <td>0.463956</td>\n",
       "      <td>2.241214</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>1.319510</td>\n",
       "      <td>-1.011186</td>\n",
       "      <td>-1.390186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>1.526142</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>0.626723</td>\n",
       "      <td>-0.139235</td>\n",
       "      <td>1.213572</td>\n",
       "      <td>0.756031</td>\n",
       "      <td>-0.225584</td>\n",
       "      <td>1.046530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0.960651</td>\n",
       "      <td>-0.209301</td>\n",
       "      <td>-0.232094</td>\n",
       "      <td>-0.071715</td>\n",
       "      <td>-0.255111</td>\n",
       "      <td>-0.128021</td>\n",
       "      <td>0.922122</td>\n",
       "      <td>1.292413</td>\n",
       "      <td>-1.011186</td>\n",
       "      <td>1.320289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096025</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.336178</td>\n",
       "      <td>-0.678067</td>\n",
       "      <td>0.288923</td>\n",
       "      <td>0.045846</td>\n",
       "      <td>-0.399901</td>\n",
       "      <td>0.743961</td>\n",
       "      <td>4.619273</td>\n",
       "      <td>-0.139311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>698 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SpMax_L   J_Dz(e)       nHM       F01       F04    NssssC       nCb  \\\n",
       "0    0.230733  1.389010 -0.232094 -0.071715  1.025951 -0.128021 -0.583471   \n",
       "1    1.261726  0.682137 -0.232094 -0.071715 -0.255111  1.167032 -0.583471   \n",
       "2    0.163050 -0.299268 -0.232094 -0.071715 -0.255111 -0.128021  0.169325   \n",
       "3    0.023820  0.060363 -0.232094 -0.071715 -0.255111 -0.128021  0.169325   \n",
       "4   -1.193804 -0.517543 -0.232094 -0.071715 -0.255111 -0.128021 -0.583471   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "693 -0.128030  0.289936 -0.232094 -0.071715 -0.255111 -0.128021 -0.583471   \n",
       "694  2.407050 -1.678164 -0.232094 -0.071715 -0.255111  2.462085 -0.583471   \n",
       "695  1.540535  1.441187  2.241214 -0.071715 -0.255111  1.167032 -0.583471   \n",
       "696  0.122419  0.463956  2.241214 -0.071715 -0.255111 -0.128021 -0.583471   \n",
       "697  0.960651 -0.209301 -0.232094 -0.071715 -0.255111 -0.128021  0.922122   \n",
       "\n",
       "            C       nCp        nO  ...      nCrt     C_026    F02_CN  \\\n",
       "0   -0.400740  1.488723 -0.034949  ... -0.096025 -0.335282  2.457302   \n",
       "1   -1.006461  2.322026 -0.034949  ... -0.096025 -0.335282 -0.336178   \n",
       "2    0.895370 -0.177883  0.642670  ... -0.096025 -0.335282 -0.336178   \n",
       "3    1.419572 -1.011186 -0.034949  ... -0.096025 -0.335282 -0.336178   \n",
       "4   -0.421137  0.655420 -1.390186  ... -0.096025 -0.335282 -0.336178   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "693 -0.273512 -0.177883 -0.034949  ... -0.096025 -0.335282 -0.336178   \n",
       "694  0.083838  0.655420 -0.034949  ...  5.059796 -0.335282 -0.336178   \n",
       "695 -1.006461  2.322026 -0.034949  ... -0.096025 -0.335282 -0.336178   \n",
       "696  1.319510 -1.011186 -1.390186  ... -0.096025 -0.335282  1.526142   \n",
       "697  1.292413 -1.011186  1.320289  ... -0.096025 -0.335282 -0.336178   \n",
       "\n",
       "        nHDon   SpMax_B   Psi_i_A        nN     SM6_B   nArCOOR        nX  \n",
       "0   -0.678067 -0.100319 -0.438917  1.213572  0.024492 -0.225584 -0.139311  \n",
       "1    1.036755 -0.489638  0.353644 -0.399901 -0.902555 -0.225584 -0.139311  \n",
       "2    0.179344  0.031227 -0.235835 -0.399901  0.100488 -0.225584 -0.139311  \n",
       "3   -0.678067  0.114656  0.382507 -0.399901 -0.009828 -0.225584 -0.139311  \n",
       "4   -0.678067 -0.975716 -1.355502 -0.399901 -0.703168 -0.225584 -0.139311  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "693 -0.678067 -0.312834 -0.692220 -0.399901  0.410503 -0.225584 -0.139311  \n",
       "694  1.036755  0.101377 -0.878552 -0.399901  0.072831 -0.225584 -0.139311  \n",
       "695  1.036755  5.132820  0.136108 -0.399901  4.457771 -0.225584  1.046530  \n",
       "696 -0.678067  0.626723 -0.139235  1.213572  0.756031 -0.225584  1.046530  \n",
       "697 -0.678067  0.288923  0.045846 -0.399901  0.743961  4.619273 -0.139311  \n",
       "\n",
       "[698 rows x 41 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalização por Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_Train_scaled=scaler.fit_transform(X_train_not_nan)\n",
    "X_train_stdScaler=pd.DataFrame(\n",
    "    data = X_Train_scaled,\n",
    "    columns=X_Train.columns\n",
    ")\n",
    "X_train_stdScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e74d2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputers = (\n",
    "        SimpleImputer(),\n",
    "        SimpleImputer(strategy=\"median\"),\n",
    "        KNNImputer()\n",
    ")\n",
    "labels = [\"SimpleImpute_mean\", \"SimpleImpute_median\", \"KNN\"]\n",
    "\n",
    "results = pd.DataFrame(index=X_train_not_nan.columns)\n",
    "for label, model in zip(labels,imputers):\n",
    "    errors=pd.DataFrame(columns = X_train_not_nan.columns)\n",
    "    for _ in range(N):\n",
    "        X_masked = X_train_stdScaler.mask(masks[_])\n",
    "        \n",
    "        model = model.fit(X_masked)\n",
    "        X_imputed = model.transform(X_masked)\n",
    "\n",
    "        errors.loc[_] = dict(zip(X_train_stdScaler.columns, \n",
    "                                 mean_squared_error(X_train_stdScaler, \n",
    "                                                    X_imputed, \n",
    "                                                    squared=False, \n",
    "                                                    multioutput=\"raw_values\")\n",
    "                                ))\n",
    "    results[label] = errors.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8f76c393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimpleImpute_mean</th>\n",
       "      <th>SimpleImpute_median</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F01</th>\n",
       "      <td>0.209905</td>\n",
       "      <td>0.193205</td>\n",
       "      <td>0.189561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.409528</td>\n",
       "      <td>0.414505</td>\n",
       "      <td>0.154902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCp</th>\n",
       "      <td>0.377293</td>\n",
       "      <td>0.382418</td>\n",
       "      <td>0.271015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HyWi_B</th>\n",
       "      <td>0.318167</td>\n",
       "      <td>0.318503</td>\n",
       "      <td>0.119724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F03_CO</th>\n",
       "      <td>0.080901</td>\n",
       "      <td>0.084408</td>\n",
       "      <td>0.042085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Me</th>\n",
       "      <td>0.304623</td>\n",
       "      <td>0.307028</td>\n",
       "      <td>0.169343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCIR</th>\n",
       "      <td>0.302958</td>\n",
       "      <td>0.350247</td>\n",
       "      <td>0.192740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpMax_A</th>\n",
       "      <td>0.379830</td>\n",
       "      <td>0.380056</td>\n",
       "      <td>0.157847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SdO</th>\n",
       "      <td>0.216545</td>\n",
       "      <td>0.217817</td>\n",
       "      <td>0.093795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nCrt</th>\n",
       "      <td>0.129451</td>\n",
       "      <td>0.115391</td>\n",
       "      <td>0.105710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpMax_B</th>\n",
       "      <td>0.533016</td>\n",
       "      <td>0.535952</td>\n",
       "      <td>0.305949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Psi_i_A</th>\n",
       "      <td>0.301281</td>\n",
       "      <td>0.303178</td>\n",
       "      <td>0.125199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nX</th>\n",
       "      <td>0.316031</td>\n",
       "      <td>0.317227</td>\n",
       "      <td>0.224088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SimpleImpute_mean  SimpleImpute_median       KNN\n",
       "F01               0.209905             0.193205  0.189561\n",
       "C                 0.409528             0.414505  0.154902\n",
       "nCp               0.377293             0.382418  0.271015\n",
       "HyWi_B            0.318167             0.318503  0.119724\n",
       "F03_CO            0.080901             0.084408  0.042085\n",
       "Me                0.304623             0.307028  0.169343\n",
       "nCIR              0.302958             0.350247  0.192740\n",
       "SpMax_A           0.379830             0.380056  0.157847\n",
       "SdO               0.216545             0.217817  0.093795\n",
       "nCrt              0.129451             0.115391  0.105710\n",
       "SpMax_B           0.533016             0.535952  0.305949\n",
       "Psi_i_A           0.301281             0.303178  0.125199\n",
       "nX                0.316031             0.317227  0.224088"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results>0].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f7a55c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImpute_mean      3.879530\n",
       "SimpleImpute_median    3.919937\n",
       "KNN                    2.151959\n",
       "dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results>0].dropna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f886e14c-978a-492d-a360-fbd0abb86f0d",
   "metadata": {},
   "source": [
    "Similarmente ao caso do MinMaxScaler, o KNN imputer obtém o menor erro nas previsões dos valores em falta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791944a8",
   "metadata": {},
   "source": [
    "# Test with Power Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "211f2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAZER FUNÇAO PARA NAO REPETIR O CODIGO DEPOIS\n",
    "\n",
    "#Normalização por Power Transform\n",
    "\n",
    "X_Train_powerTscaled=PowerTransformer().fit_transform(X_train_not_nan)\n",
    "X_train_powerTscaler=pd.DataFrame(\n",
    "    data = X_Train_powerTscaled,\n",
    "    columns=X_Train.columns\n",
    ")\n",
    "#X_train_powerTscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3f901433",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(index=X_train_not_nan.columns)\n",
    "for label, model in zip(labels,imputers):\n",
    "    errors=pd.DataFrame(columns = X_train_not_nan.columns)\n",
    "    for _ in range(N):\n",
    "        X_masked = X_train_powerTScaler.mask(masks[_])\n",
    "        \n",
    "        model = model.fit(X_masked)\n",
    "        X_imputed = model.transform(X_masked)\n",
    "\n",
    "        errors.loc[_] = dict(zip(X_train_powerTscaler.columns, \n",
    "                                 mean_squared_error(X_train_powerTscaler, \n",
    "                                                    X_imputed, \n",
    "                                                    squared=False, \n",
    "                                                    multioutput=\"raw_values\")\n",
    "                                ))\n",
    "    results[label] = errors.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1c6702cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImpute_mean      4.026007\n",
       "SimpleImpute_median    4.141768\n",
       "KNN                    1.914111\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results>0].dropna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13240edc",
   "metadata": {},
   "source": [
    "As we can see, KNN has the minimum error in every scalling method, so we will only use KNN-Imputer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b989d",
   "metadata": {},
   "source": [
    "# Scale and impute the rest of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c90a3",
   "metadata": {},
   "source": [
    "Perform imputation of missing values before scaling, as scaling could lead to distorted data if the missing values are not first replaced. This is because some calculations may include the missing values and their presence could lead to skewed results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af25d77",
   "metadata": {},
   "source": [
    "## Impute data with knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6df904d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.77685373, 2.40874116, 0.        , ..., 6.96722794, 0.        ,\n",
       "        0.        ],\n",
       "       [4.20757702, 3.40555706, 0.        , ..., 7.70063609, 0.        ,\n",
       "        0.        ],\n",
       "       [4.65      , 4.0313    , 0.        , ..., 8.131     , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [4.29286534, 3.15616198, 0.        , ..., 8.31702029, 0.        ,\n",
       "        0.        ],\n",
       "       [4.596     , 3.4161    , 2.        , ..., 8.812     , 0.        ,\n",
       "        2.        ],\n",
       "       [5.0138996 , 2.96835616, 0.        , ..., 8.8007641 , 2.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the KNNImputer\n",
    "imputer = KNNImputer()\n",
    "\n",
    "X_Train_imputed = imputer.fit_transform(X_Train)\n",
    "\n",
    "X_Train_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547ad57",
   "metadata": {},
   "source": [
    "## Scale with PowerTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f558b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer()\n",
    "X_Train_imputed_powerT = pt.fit_transform(X_Train_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5525b",
   "metadata": {},
   "source": [
    "# Using RFs for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aae5dce",
   "metadata": {},
   "source": [
    "Fitting a tree find the best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fb1d2a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importances:  [8.23988104e-03 2.12618470e-02 2.48864917e-01 3.12028883e-03\n",
      " 5.47606973e-02 1.07662200e-01 4.33974418e-02 1.42828950e-02\n",
      " 9.50600090e-03 5.02455626e-03 8.80909238e-02 2.29096233e-02\n",
      " 1.13669699e-02 1.86241705e-02 1.07720765e-02 1.46932586e-02\n",
      " 1.89888605e-02 1.64687295e-02 7.60795629e-04 6.51909379e-03\n",
      " 9.24109738e-05 4.48890665e-02 4.38464263e-03 1.41660015e-04\n",
      " 8.58188805e-04 1.51889169e-04 1.08706637e-02 1.11504208e-02\n",
      " 1.94641808e-04 1.38882741e-02 1.38802928e-02 3.15696164e-02\n",
      " 7.46717594e-03 4.62407919e-02 3.99746537e-03 2.55049900e-02\n",
      " 2.38750647e-02 5.22950970e-03 8.17522961e-03 1.06066515e-03\n",
      " 2.10621132e-02]\n",
      "Default threshold:  -inf\n",
      "The features selected are columns:  [ 2  4  5 10 33]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "N,M=X_Train_imputed.shape\n",
    "\n",
    "rfr=RandomForestRegressor(random_state=0)\n",
    "#threshold is minus infinity\n",
    "sel = SelectFromModel(estimator=rfr, threshold=-np.inf, max_features=5)\n",
    "\n",
    "sel.fit(X_Train_imputed_powerT, y_Train)\n",
    "\n",
    "print(\"Importances: \", sel.estimator_.feature_importances_)\n",
    "\n",
    "print(\"Default threshold: \", sel.threshold_)\n",
    "\n",
    "features=sel.get_support()\n",
    "Features_selected =np.arange(M)[features]\n",
    "print(\"The features selected are columns: \", Features_selected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a4cdb",
   "metadata": {},
   "source": [
    "### Another way to do the same. choose later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "14433e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nHM', 'NssssC', 'F03', 'F02_CN', 'F04']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_Train_imputed_powerT, y_Train)\n",
    "\n",
    "\n",
    "# create a dictionary to store your feature importance scores\n",
    "feature_imp = dict(zip(X_Train.columns, rfr.feature_importances_))\n",
    "\n",
    "# specify the number of variables you want\n",
    "num_vars = 5 # insert number of desired variables\n",
    "\n",
    "# create an empty list to store\n",
    "selected_features = []\n",
    "\n",
    "# loop through each variable, sorted by their importance scores\n",
    "for variable, score in sorted(feature_imp.items(), key=lambda x: x[1], reverse=True):\n",
    "  # add the variable if below the specified number of variables\n",
    "  if len(selected_features) < num_vars:\n",
    "    selected_features.append(variable)\n",
    "\n",
    "selected_features\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
